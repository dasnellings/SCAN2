import pandas as pd
from snakemake.utils import R


# Read in the GATK parallelization regions file
gatk_region_tab = pd.read_table(config["gatk_region_file"])
gatk_region_chrs = gatk_region_tab['chr']
gatk_region_starts = gatk_region_tab['start']
gatk_region_stops = gatk_region_tab['stop']

# Determine the number of chunks and get GATK compatible region strings
gatk_chunks = range(1, 1 + len(gatk_region_chrs))
gatk_regions = [ "%s:%d-%s" % (gatk_region_chrs[i], int(gatk_region_starts[i])+1, gatk_region_stops[i]) for i in range(0, len(gatk_region_chrs)) ]

# Get the list of unique chromosome names in the region list, preserving order
chrs = []
[ chrs.append(s) for s in gatk_region_chrs if not chrs.count(s) ]



wildcard_constraints:
    gatk_chunk="\d+",
    gatk_mmq="\d+",
    hsnp_type="cigar|spikein"



rule all:
    input:
        "scansnv/h25/somatic_genotypes.rda",
        "scansnv/h25/hsnp_spikein_genotypes.rda"



rule gatk_gather:
    input:
        vcf=lambda wildcards:
                expand("gatk/hc_raw.mmq{gatk_mmq}_chunk{gatk_chunk}.vcf",
                       gatk_mmq=wildcards.gatk_mmq, gatk_chunk=gatk_chunks)
    output:
        vcf="gatk/hc_raw.mmq{gatk_mmq}.vcf"
    params:
        lambda wildcards:
            ' '.join(expand("-V gatk/hc_raw.mmq{gatk_mmq}_chunk{gatk_chunk}.vcf",
                            gatk_mmq=wildcards.gatk_mmq, gatk_chunk=gatk_chunks))
    shell:
        "gatk org.broadinstitute.gatk.tools.CatVariants"
        "    -Xmx3G -Xms3G"
        "    -R {config[humref]}"
        "    {params}"
        "    -out {output.vcf}"
        "    -assumeSorted"



rule gatk_scatter:
    input:
        bam=expand("{sample}.bam", sample=config['samples']),
    output:
        vcf="gatk/hc_raw.mmq{gatk_mmq}_chunk{gatk_chunk}.vcf"
    params:
        bamlist=expand("-I {sample}.bam", sample=config['samples']),
        regionflag=lambda wildcards:
            "-L " + gatk_regions[int(wildcards.gatk_chunk) - 1],
        mmq="{gatk_mmq}"
    shell:
        "gatk -Xmx8G -Xms8G "
        "    -T HaplotypeCaller"
        "    -R {config[humref]}"
        "    --dontUseSoftClippedBases -l INFO"
        "    --dbsnp {config[dbsnp]}"
        "    -rf BadCigar "
        "    -mmq {params.mmq}"
        "    {params.bamlist}"
        "    {params.regionflag}"
        "    -o {output.vcf}"



rule shapeit_gather:
    input:
        expand("shapeit/chr{chr}/phased_hsnps.vcf", chr=chrs)
    output:
        vcf="shapeit/phased_hsnps.vcf"
    params:
        vcfs=' '.join(expand("-V shapeit/chr{chr}/phased_hsnps.vcf", chr=chrs))
    shell:
        "gatk org.broadinstitute.gatk.tools.CatVariants"
        "    -Xmx3G -Xms3G"
        "    -R {config[humref]}"
        "    {params.vcfs}"
        "    -out {output}"
        "    -assumeSorted"



rule shapeit_scatter:
    input:
        "shapeit/chr{chr}/hc_raw.mmq60.chr{chr}.vcf"
    output:
        "shapeit/chr{chr}/phased_hsnps.vcf"
    params:
        excludefile="shapeit/chr{chr}/shapeit_check.snp.strand.exclude",
        tmpout="shapeit/chr{chr}/chr{chr}.phased",
        tmpout2="shapeit/chr{chr}/phased.vcf",
        checklog="shapeit/chr{chr}/shapeit_check.log",
        phaselog="shapeit/chr{chr}/shapeit_phase.log",
        convertlog="shapeit/chr{chr}/shapeit_convert.log",
        gmap="genetic_map_chr{chr}",
        hap="1000GP_Phase3_chr{chr}",
        leg="1000GP_Phase3_chr{chr}",
        gmap_extra_x=lambda wildcards: '_nonPAR' if wildcards.chr == 'X' else '',
        extra_x=lambda wildcards: '_NONPAR' if wildcards.chr == 'X' else '',
        xflag=lambda wildcards: '--chrX' if wildcards.chr == 'X' else ''
    shell:
        # Note the "|| true" after shapeit -check: this is because shapeit
        # -check returns non-0 when it finds any number of problematic SNPs.
        # This CAN be dangerous as we're avoiding Snakemake's pipefail error
        # detection method.
        "shapeit -check"
        "    --input-vcf={input}"
        "    --output-log {params.checklog}"
        "    -M {config[shapeit_refpanel]}/{params.gmap}{params.gmap_extra_x}_combined_b37.txt"
        "    --input-ref {config[shapeit_refpanel]}/{params.hap}{params.extra_x}.hap.gz"
        "        {config[shapeit_refpanel]}/{params.leg}{params.extra_x}.legend.gz "
        "        {config[shapeit_refpanel]}/1000GP_Phase3.sample || true ; "
        "shapeit"
        "    --input-vcf={input}"
        "    --output-log {params.phaselog}"
        "    -M {config[shapeit_refpanel]}/{params.gmap}{params.gmap_extra_x}_combined_b37.txt"
        "    --input-ref {config[shapeit_refpanel]}/{params.hap}{params.extra_x}.hap.gz"
        "        {config[shapeit_refpanel]}/{params.leg}{params.extra_x}.legend.gz "
        "        {config[shapeit_refpanel]}/1000GP_Phase3.sample"
        "    --exclude-snp {params.excludefile}"
        "    {params.xflag}"
        "    -O {params.tmpout} ; "
        "shapeit -convert "
        "    --output-log {params.convertlog}"
        "    --input-haps {params.tmpout} --output-vcf {params.tmpout2} ; "
        "awk '$10 == \"1|0\" || $10 == \"0|1\" || $1 ~ /^#/' {params.tmpout2}"
        "    | sed -e\"s/{config[bulk_sample]}/phasedgt/g\" > {output}"
    


rule shapeit_prepare:
    input:
        "gatk/hc_raw.mmq60.vcf"
    output:
        "shapeit/chr{chr}/hc_raw.mmq60.chr{chr}.vcf"
    params:
        chr="{chr}"
    shell:
        "gatk -Xmx6G -Xms6G"
        "    -T SelectVariants"
        "    -R {config[humref]}"
        "    -V {input}"
        "    -selectType SNP"
        "    -sn {config[bulk_sample]}"
        "    -restrictAllelesTo BIALLELIC"
        "    -env -trimAlternates"
        "    -L {params.chr}"
        "    -o {output}"



rule training_hsnps_helper:
    input:
        joint_vcf="gatk/hc_raw.mmq60.vcf",
        phased_vcf="shapeit/phased_hsnps.vcf"
    output:
        tab="ab_model/{sample}/hsnps.tab",
        combined_vcf="ab_model/{sample}/hsnps.vcf",
        tmp_vcf="ab_model/{sample}/hsnps_helper_tmp.vcf",
    params:
        sn="{sample}"
    shell:
        "gatk -Xmx6G -Xms6G"
        "    -R {config[humref]}"
        "    -T CombineVariants"
        "    -V {input.joint_vcf}"
        "    -V {input.phased_vcf}"
        "    -o {output.tmp_vcf} ;"
        "gatk -Xmx6G -Xms6G"
        "    -R {config[humref]}"
        "    -T SelectVariants"
        "    -V {output.tmp_vcf}"
        "    -sn {params.sn}"
        "    -sn phasedgt"
        "    -env -trimAlternates"
        "    -select 'vc.getGenotype(\"'{params.sn}'\").isCalled()'"
        "    -select 'vc.getGenotype(\"phasedgt\").isCalled()'"
        "    -select 'vc.isBiallelic()'"
        "    -selectType SNP"
        "    -o {output.combined_vcf} ; "
        "{config[scripts]}/totab.phase.sh {output.combined_vcf} {output.tab}"



rule training_hsnps:
    input:
        "ab_model/{sample}/hsnps.tab"
    output:
        rda="ab_model/{sample}/training.rda"
    run:
        R("""
            data <- read.table("{input}",
                header=TRUE, stringsAsFactors=FALSE,
                colClasses=c(chr='character'))
            save(data, file="{output}")
        """)



rule abmodel_fit:
    input:
        lambda wildcards: 
            expand("ab_model/{sample}/chr{chr}/fit_step{abmodel_steps}.rda",
                sample=wildcards.sample, chr=chrs,
                abmodel_steps=config['abmodel_steps'])
    output:
        "ab_model/{sample}/fits.rda"
    params:
        infiles=lambda wildcards, input:
            "c(" + ', '.join([ "'" + f + "'" for f in input ]) + ")",
    run:
        R("""
            x <- lapply({params.infiles}, function(f) {{
                load(f)
                list(chr=chr, fit=fit)
            }})
            fits <- lapply(x, function(xx) xx$fit)
            names(fits) <- lapply(x, function(xx) xx$chr)
            save(fits, file="{output}")
        """)



rule abmodel_gather_by_chrom:
    input:
        lambda wildcards:
            expand("ab_model/{sample}/chr{chr}/logp_samples_step{abmodel_step}.{abmodel_chunk}.rda",
                sample=wildcards.sample,
                chr=wildcards.chr,
                abmodel_step=wildcards.abmodel_step,
                abmodel_chunk=range(1, config["abmodel_chunks"]+1))
    output:
        fit="ab_model/{sample}/chr{chr}/fit_step{abmodel_step}.rda",
        range="ab_model/{sample}/chr{chr}/param_ranges_step{abmodel_step}.rda"
    params:
        infiles=lambda wildcards, input:
            "c(" + ', '.join("'" + f + "'" for f in input) + ")",
        chr="{chr}"
    run:
        R("""
            x <- do.call(rbind, 
                lapply({params.infiles}, function(f) {{
                    load(f)
                    logp.samples
                }})
            )
            dn <- dimnames(x)
            x <- as.matrix(x)
            # swapping columns (1,2) and (3,4) to force b < d.
            # ifelse returns a value the same shape as the first argument
            logi.mat <- matrix(rep(x[,2] < x[,4], times=5), ncol=5)
            x <- as.data.frame(ifelse(logi.mat, x, x[,c(3,4,1,2,5)]))
            dimnames(x) <- dn
            x <- x[order(x[,5], decreasing=TRUE),]

            # The highest logp value (x[,5]) is the best fit
            fit <- x[1,,drop=FALSE]
            chr <- "{params.chr}"
            save(chr, fit, file="{output.fit}")

            # Use the top 50 logp values to build a new parameter range
            x[,2] <- log10(x[,2])   # b and d bounds are in log10 space
            x[,4] <- log10(x[,4])
            bounds <- apply(head(x[,-5], 50), 2, range)
            colnames(bounds) <- colnames(x)[-5]
            save(bounds, file="{output.range}")
        """)



# Every step with abmodel_step > 1 will add the previous step's output
# to its input.  This allows the recursion to terminate when step=1.
def abmodel_scatter_input(wildcards):
    prf = ''
    d = dict()
    d['training'] = "ab_model/{sample}/training.rda",
    if int(wildcards.abmodel_step) > 1:
         prf = expand("ab_model/{sample}/chr{chr}/param_ranges_step{abmodel_prev_step}.rda",
                sample=wildcards.sample,
                chr=wildcards.chr,
                abmodel_prev_step=int(wildcards.abmodel_step) - 1)
         d['param_ranges'] = prf
    return d

rule abmodel_scatter:
    input:
        unpack(abmodel_scatter_input)  
        #"ab_model/{sample}/training.rda"
    output:
        "ab_model/{sample}/chr{chr}/logp_samples_step{abmodel_step}.{abmodel_chunk}.rda"
    params:
        chr="{chr}",
        seed="{abmodel_chunk}",
        step="{abmodel_step}",
        paramfile=lambda wildcards, input: \
            input.param_ranges if wildcards.abmodel_step != '1' else ''
    benchmark:
        "ab_model/{sample}/chr{chr}/benchmark_step{abmodel_step}.{abmodel_chunk}.tsv"
    run:
        R("""
            library(scansnv)
            alim <- c(-7, 2)
            blim <- c(2, 4)
            clim <- c(-7, 2)
            dlim <- c(2, 6)
            if ({params.step} > 1) {{
                load("{params.paramfile}")
                alim <- bounds[,1]
                blim <- bounds[,2]
                clim <- bounds[,3]
                dlim <- bounds[,4]
            }}
            load("{input.training}")
            data <- data[data$chr == "{params.chr}",]
            ctx <- abmodel.approx.ctx(x=data$pos,
                y=data$hap1, d=data$hap1+data$hap2,
                hsnp.chunksize={config[abmodel_hsnp_chunksize]}
            )
            logp.samples <- abmodel.sample(
                n={config[abmodel_samples_per_chunk]},
                alim=alim, blim=blim, clim=clim, dlim=dlim,
                ctx=ctx,
                seed={params.seed})
            save(logp.samples, file="{output}")
        """)



rule scansnv_vcftotab:
    input:
        "gatk/hc_raw.mmq{gatk_mmq}.vcf"
    output:
        vcf="scansnv/mmq{gatk_mmq}.vcf",
        tab="scansnv/mmq{gatk_mmq}.tab"
    shell:
        "gatk -Xmx10G -Xms10G"
        "   -T SelectVariants"
        "   -R {config[humref]}"
        "   -V {input}"
        "   -selectType SNP -restrictAllelesTo BIALLELIC"
        "   -env -trimAlternates"
        "   -select 'vc.getGenotype(\"{config[bulk_sample]}\").isCalled()'"
        "   -o {output.vcf} ; "
        "{config[scripts]}/totab.sh {output.vcf} {output.tab}"



rule scansnv_sample_hsnps:
    input:
        "shapeit/phased_hsnps.vcf"
    output:
        "scansnv/hsnp_{hsnp_type}_positions.chr{chr}.tab"
    params:
        chr="{chr}",
        nsamples=lambda wildcards:
            int(config['hsnp_' + wildcards.hsnp_type + '_nsamples'])
    run:
        R("""
            vcf <- read.table("{input}", stringsAsFactors=TRUE, header=F,
                            comment="#", colClasses=c(V1='character'))
            vcf <- vcf[vcf$V1 == "{params.chr}",]
            hsnp.sample <- vcf[sample(nrow(vcf), size={params.nsamples}),]
            colnames(hsnp.sample)[c(1:2,4:5)] <- c('chr', 'pos', 'refnt', 'altnt')
            write.table(hsnp.sample[,c(1:2,4:5)], file="{output}", quote=F,
                row.names=FALSE, sep='\t')
        """)



rule scansnv_somatic_sites:
    input:
        "scansnv/mmq60.tab"
    output:
        "scansnv/somatic_positions.chr{chr}.tab"
    params:
        chr="{chr}"
    run:
        R("""
            # Use a very sensitive definition of somatic site here
            # At least: 0 alt reads in bulk, not a no-call, not in dbsnp
            # and at least 2 non-bulk reads.
            tab <- read.table("{input}", stringsAsFactors=FALSE, header=TRUE,
                            comment="#", colClasses=c(chr='character'))
            bulk.sample <- make.names("{config[bulk_sample]}")
            bulk.idx <- which(colnames(tab) == bulk.sample)
            bulk.alt <- bulk.idx +  2
            sc.alts <- which(grepl("alt", colnames(tab)) &
                             colnames(tab) != colnames(tab)[bulk.alt] &
                             colnames(tab) != "altnt")
            cat("Using data:\n")
            for (i in 1:ncol(tab)) {{
                s <- ifelse(i %in% sc.alts,
                    "[SC]",
                    ifelse(i == bulk.alt, "[BULK]", ""))
                cat(sprintf("%8s %s\n", s, colnames(tab)[i]))
            }}

            candidate.somatics <-
                tab[tab[,bulk.alt] == 0 &
                    tab[,bulk.idx] == '0/0' &
                    tab$dbsnp == '.' &
                    rowSums(as.matrix(tab[,sc.alts])) > 1 &
                    tab$chr == "{params.chr}",]
            write.table(candidate.somatics[,c(1:2, 4:5)], sep="\t",
                quote=FALSE, row.names=FALSE, file="{output}")
        """)



rule scansnv_count_cigars:
    input:
        sites="scansnv/{vartype}_positions.chr{chr}.tab",
        bam="{sample}.bam"
    output:
        txt="scansnv/{sample}/{vartype}_cigars.chr{chr}.txt",
        tab="scansnv/{sample}/{vartype}_cigars.chr{chr}.tab"
    shell:
        "{config[scripts]}/get_cigars.sh {input.sites} {input.bam} {output.txt} ; "
        "{config[scripts]}/count_cigars.py {output.txt} > {output.tab}"



rule scansnv_cigar_gather:
    input:
        lambda wildcards:
            expand("scansnv/{sample}/{vartype}_cigars.chr{chr}.tab",
                sample=wildcards.sample, vartype=wildcards.vartype, chr=chrs)
    output:
        "scansnv/{sample}/{vartype}_cigars.tab"
    params:
        infiles=lambda wildcards, input:
            "c(" + ", ".join([ '"' + f + '"' for f in input ]) + ")"
    run:
        R("""
            cigars <- do.call(rbind, lapply({params.infiles}, function(f) {{
                read.table(f, header=T)
            }}))
            write.table(cigars, file="{output}", quote=FALSE, row.names=FALSE,
                sep="\t")
        """)



rule scansnv_estimate_ab_scatter:
    input:
        fits="ab_model/{sample}/fits.rda",
        training="ab_model/{sample}/training.rda",
        sites="scansnv/{type}_positions.chr{chr}.tab"
    output:
        "scansnv/{sample}/{type}_ab.chr{chr}.rda"
    params:
        flag=lambda wildcards:
            "somatic" if wildcards.type == 'somatic' else 'hsnp_spikein'
    shell:
        "{config[scripts]}/estimate_ab.R"
        "   {input.fits} {input.training} {input.sites} {params} {output}"
        


rule scansnv_estimate_ab_gather:
    input:
        lambda wildcards:
            expand("scansnv/{sample}/{type}_ab.chr{chr}.rda",
                type=wildcards.type, sample=wildcards.sample, chr=chrs)
    output:
        "scansnv/{sample}/{type}_ab.rda"
    params:
        infiles=lambda wildcards, input:
            "c(" + ", ".join([ "'" + f + "'" for f in input ]) + ")"
    run:
        R("""
            ab <- do.call(rbind, lapply({params.infiles},
                function(f) {{ load(f); ab }}))
            save(ab, file="{output}")
        """)



rule scansnv_fdr_tuning:
    input:
        mmq60="scansnv/mmq60.tab",
        hsnps="ab_model/{sample}/training.rda",
        som_sites=expand("scansnv/somatic_positions.chr{chr}.tab", chr=chrs)
    output:
        "scansnv/{sample}/fdr_tuning.rda"
    params:
        sample="{sample}",
    shell:
        "{config[scripts]}/fdr_tuning.R"
        "   {input.mmq60}"
        "   {input.hsnps}"
        "   {params.sample}"
        "   {output}"
        "   {input.som_sites}"



rule scansnv_hsnp_make_spikeins:
    input:
        "scansnv/{sample}/hsnp_spikein_ab.rda"
    output:
        abrda="scansnv/{sample}/hsnp_spikein{n}_ab.rda",
        postab="scansnv/{sample}/hsnp_spikein{n}_positions.tab"
    params:
        n="{n}",
        abfiles=lambda wildcards, input:
            "c(" + ', '.join([ '"' + f + '"' for f in input ]) + ")"
    run:
        R("""
            load("{input}") # loads 'ab'
            n <- {params.n}
            step <- {config[hsnp_spikein_size]}
            ab <- ab[(1 + (n - 1)*step):(n*step),]
            write.table(ab[,c(1:4)], sep="\t",
                quote=FALSE, row.names=FALSE, file="{output.postab}")
            save(ab, file="{output.abrda}")
        """)



rule scansnv_fdr_tuning_spikein:
    input:
        mmq60="scansnv/mmq60.tab",
        hsnps="ab_model/{sample}/training.rda",
        spikein="scansnv/{sample}/hsnp_spikein{n}_positions.tab",
        som_sites=expand("scansnv/somatic_positions.chr{chr}.tab", chr=chrs)
    output:
        "scansnv/{sample}/fdr_tuning_spikein{n}.rda"
    params:
        sample="{sample}",
    shell:
        "{config[scripts]}/fdr_tuning.R"
        "   {input.mmq60}"
        "   {input.hsnps}"
        "   {params.sample}"
        "   {output}"
        "   {input.spikein}"
        "   {input.som_sites}"
    


rule scansnv_genotype_scatter:
    input:
        mmq60="scansnv/mmq60.tab",
        mmq1="scansnv/mmq1.tab",
        som_ab="scansnv/{sample}/{type}_ab.chr{chr}.rda",
        som_cigars="scansnv/{sample}/{type}_cigars.chr{chr}.tab",
        hsnp_cigars="scansnv/{sample}/hsnp_cigar_cigars.tab",
        fdr_tuning="scansnv/{sample}/fdr_tuning.rda",
    output:
        "scansnv/{sample}/{type}_genotypes.chr{chr}.rda"
    params:
        sc_sample="{sample}"
    shell:
        "{config[scripts]}/genotype.R"
        "   {input.mmq60} {input.mmq1}"
        "   {params.sc_sample} {config[bulk_sample]}"
        "   {input.som_ab} {input.som_cigars} {input.hsnp_cigars}"
        "   {output} {config[fdr]} {input.fdr_tuning} somatic"



rule scansnv_genotype_gather:
    input:
        lambda wildcards:
            expand("scansnv/{sample}/somatic_genotypes.chr{chr}.rda",
                sample=wildcards.sample, chr=chrs)
    output:
        "scansnv/{sample}/somatic_genotypes.rda"
    params:
        files=lambda wildcards, input:
            "c(" + ", ".join([ "'" + f + "'" for f in input ]) + ")"
    run:
        R("""
            somatic <- do.call(rbind,
                lapply({params.files}, function(f) {{
                    load(f)
                    gt$somatic
                }})
            )

            save(somatic, file="{output}")
        """)



rule scansnv_genotype_spikein_scatter:
    input:
        mmq60="scansnv/mmq60.tab",
        mmq1="scansnv/mmq1.tab",
        som_ab="scansnv/{sample}/hsnp_spikein{n}_ab.rda",
        som_cigars="scansnv/{sample}/hsnp_spikein_cigars.tab",
        hsnp_cigars="scansnv/{sample}/hsnp_cigar_cigars.tab",
        fdr_tuning="scansnv/{sample}/fdr_tuning_spikein{n}.rda",
    output:
        "scansnv/{sample}/hsnp_spikein{n}_genotypes.rda"
    params:
        sc_sample="{sample}"
    shell:
        "{config[scripts]}/genotype.R"
        "   {input.mmq60} {input.mmq1}"
        "   {params.sc_sample} {config[bulk_sample]}"
        "   {input.som_ab} {input.som_cigars} {input.hsnp_cigars}"
        "   {output} {config[fdr]} {input.fdr_tuning} spikein"


rule scansnv_genotype_spikein_gather:
    input:
        lambda wildcards:
            expand("scansnv/{sample}/hsnp_spikein{n}_genotypes.rda",
                sample=wildcards.sample, n=range(1, config['spikein_replicates']+1))
    output:
        "scansnv/{sample}/hsnp_spikein_genotypes.rda"
    params:
        infiles=lambda wildcards, input:
            "c(" + ", ".join([ '"' + f + '"' for f in input ]) + ")"
    run:
        R("""
            spikeins <- do.call(rbind, lapply({params.infiles},
                function(f) {{
                    load(f)
                    gt$somatic
                }}
            ))

            save(spikeins, file="{output}")
        """)

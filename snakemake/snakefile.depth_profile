# vim: syntax=python

# Basepair resolution depth profiles are used for extrapolation of mutation burden.
# There are two tools for calculating this bp-res depth:
#       1. GATK DepthOfCoverage
#       2. samtools depths
# GATK DepthOfCoverage is ~100x slower than samtools depth and gives comparable
# output. Because of this, the two tools are parallelized differently. GATK uses
# analysis_regions and samtools depths splits jobs per chromosome.

rule depth_profile_region_summarize_per_sample:
    input:
        config_yaml='scan.yaml',
        tab="depth_profile/{depth_method}_joint_depth_matrix.tab.gz",
        tabidx="depth_profile/{depth_method}_joint_depth_matrix.tab.gz.tbi"
    output:
        rda="depth_profile/{sample}_{depth_method}_depth_table.rda"
    params:
        sc_sample="{sample}"
    benchmark:
        "depth_profile/benchmark_{sample}_{depth_method}_region_summarize.txt"
    resources:
        # This memory value depends strongly on the size of GATK regions. Here we
        # assume 10 Mb chunks and 10 bytes per position per sample.
        #
        # it is unclear to me why this much RAM is needed when reading in chunks
        # and reading only 2 samples at a time, but these values are derived from
        # many real world runs. the max. memory used was 1555 MB per thread; did
        # not scale with number of samples in each batch, as expected. give 1800 MB,
        # a little extra headroom.
        mem_mb=lambda wildcards, input, threads: 1800 * threads
    threads: config['digest_depth_n_cores']
    shell:
        """
        {config[scripts]}/digest_depth.R \
            {params.sc_sample} {input.config_yaml} {input.tab} \
            {output.rda} {threads}
        """


rule depth_profile_make_arg_file:
    input:
        files=lambda wildcards: expand("depth_profile/{{depth_method}}/region_{analysis_region}.txt",
            analysis_region=config['analysis_regions'] if wildcards.depth_method == "gatkdocov" else config['chrs'])
    output:
        argfile="depth_profile/{depth_method}_region_arg_file.txt"
    localrule: True
    run:
        with open(output.argfile, 'w') as f:
            for infile in input.files:
                f.write(str(infile) + "\n")


rule depth_profile_gather:
    input:
        # There may be 1000s of regions (and thus files) in larger projects.  There
        # is a limit to how long a command line can be, so read the file names from
        # a file rather than pasting them into a command.
        argfile="depth_profile/{depth_method}_region_arg_file.txt",
        files=lambda wildcards: expand("depth_profile/{{depth_method}}/region_{analysis_region}.txt",
            analysis_region=config['analysis_regions'] if wildcards.depth_method == "gatkdocov" else config['chrs'])
    output:
        tabgz="depth_profile/{depth_method}_joint_depth_matrix.tab.gz",
        tabidx="depth_profile/{depth_method}_joint_depth_matrix.tab.gz.tbi"
    log:
        "depth_profile/{depth_method}_joint_depth_matrix.log"
    benchmark:
        "depth_profile/benchmark_{depth_method}_joint_depth_matrix.txt"
    threads: 4
    resources:
        mem_mb=1000
    shell:
        # Use the header from the first file; they should all be identical
        """
        (grep -m1 '^#' $(head -1 {input.argfile}) ; \
         cat {input.argfile} | while read line; do \
            tail -n +2 $line ; \
         done) \
        | bgzip --threads {threads} -c > {output.tabgz}
        tabix -p vcf -S 1 {output.tabgz}
        """


# Needs to match GATK read filters (e.g., mapping quality, additional
# default HaplotypeCaller read filters) to be meaningful.
rule gatkdocov_depth_profile_scatter:
    input:
        argfile="gatk/arg_file_bams.list"
    output:
        tmp=temp("depth_profile/gatkdocov/region_{analysis_region}.tmp.txt"),
        txt=temp("depth_profile/gatkdocov/region_{analysis_region}.txt")
    log:
        "depth_profile/gatkdocov/region_{analysis_region}.log"
    benchmark:
        "depth_profile/gatkdocov/benchmark_depthofcoverage.region_{analysis_region}.txt"
    params:
        regionflag="-L {analysis_region}"
    threads: 1
    resources:
        mem_mb=6000
    shell:
        """
        gatk DepthOfCoverage \
            --java-options '-Xmx5G -Xms5G' \
            --arguments_file {input.argfile} \
            -R {config[ref]} \
            {params.regionflag} \
            --minimum-mapping-quality 60 \
            --read-filter NotSecondaryAlignmentReadFilter \
            --read-filter GoodCigarReadFilter \
            --read-filter NonZeroReferenceLengthAlignmentReadFilter \
            --read-filter PassesVendorQualityCheckReadFilter \
            --read-filter MappedReadFilter \
            --read-filter MappingQualityAvailableReadFilter \
            --read-filter NotDuplicateReadFilter \
            --read-filter MappingQualityReadFilter \
            --read-filter WellformedReadFilter \
            --omit-interval-statistics true \
            --omit-locus-table true \
            --omit-per-sample-statistics true \
            --output-format TABLE \
            -O {output.tmp}
        {config[scripts]}/totab.depth_profile.sh {output.tmp} {output.txt} \
        """


rule make_samtoolsdepth_argfile:
    input:
        files=config['bam_map'].values()
    output:
        argfile="depth_profile/samtoolsdepth/bam_arg_file.txt"
    localrule: True
    run:
        with open(output.argfile, 'w') as f:
            for infile in input.files:
                f.write(str(infile) + "\n")


# Needs to match GATK read filters (e.g., mapping quality, additional
# default HaplotypeCaller read filters) to be meaningful.
rule samtoolsdepth_depth_profile_scatter:
    input:
        argfile="depth_profile/samtoolsdepth/bam_arg_file.txt"
    output:
        txt=temp("depth_profile/samtoolsdepth/region_{analysis_region}.txt")
    log:
        "depth_profile/samtoolsdepth/region_{analysis_region}.log"
    benchmark:
        "depth_profile/samtoolsdepth/benchmark_samtoolsdepth.region_{analysis_region}.txt"
    params:
        regionflag="-r {analysis_region}"
    threads: 1
    resources:
        mem_mb=1000
    shell:
        # First two lines create a header in the correct order
        """
        (echo -n "#chr pos "|tr ' ' '\t' ;
         cat {input.argfile} | samtools samples | cut -f1 | tr '\n' '\t' | sed -e 's/\t$//' ;
         echo "" ;
         samtools depth \
            -a \
            -f {input.argfile} \
            --reference {config[ref]} \
            {params.regionflag} \
            --min-MQ 60 \
            --excl-flags UNMAP,SECONDARY,QCFAIL,DUP,SUPPLEMENTARY ) > {output.txt}
        """

# vim: syntax=python

rule depth_profile_region_summarize_per_sample:
    input:
        config_yaml='scan.yaml',
        tab="depth_profile/joint_depth_matrix.tab.gz",
        tabidx="depth_profile/joint_depth_matrix.tab.gz.tbi"
    output:
        rda="depth_profile/{sample}_depth_table.rda"
    params:
        sc_sample="{sample}"
    benchmark:
        "depth_profile/benchmark_{sample}_region_summarize.txt"
    resources:
        # This memory value depends strongly on the size of GATK regions. Here we
        # assume 10 Mb chunks and 10 bytes per position per sample.
        #
        # it is unclear to me why this much RAM is needed when reading in chunks
        # and reading only 2 samples at a time, but these values are derived from
        # many real world runs. the max. memory used was 1555 MB per thread; did
        # not scale with number of samples in each batch, as expected. give 1800 MB,
        # a little extra headroom.
        mem_mb=lambda wildcards, input, output, threads: 1800 * threads
    threads: config['digest_depth_n_cores']
    shell:
        """
        {config[scripts]}/digest_depth.R \
            {params.sc_sample} {input.config_yaml} {input.tab} \
            {output.rda} {threads}
        """


rule depth_profile_make_arg_file:
    input:
        files=expand("depth_profile/gatk_depthofcoverage/region_{analysis_region}.txt",
            analysis_region=config['analysis_regions'])
    output:
        argfile="depth_profile/region_arg_file.txt"
    localrule: True
    run:
        with open(output.argfile, 'w') as f:
            for infile in input.files:
                f.write(str(infile) + "\n")


rule depth_profile_gather:
    input:
        # There may be 1000s of regions (and thus files) in larger projects.  There
        # is a limit to how long a command line can be, so read the file names from
        # a file rather than pasting them into a command.
        argfile="depth_profile/region_arg_file.txt",
        files=expand("depth_profile/gatk_depthofcoverage/region_{analysis_region}.txt",
            analysis_region=config['analysis_regions'])
    output:
        tabgz="depth_profile/joint_depth_matrix.tab.gz",
        tabidx="depth_profile/joint_depth_matrix.tab.gz.tbi"
    log:
        "depth_profile/joint_depth_matrix.log"
    benchmark:
        "depth_profile/benchmark_joint_depth_matrix.txt"
    threads: 4
    resources:
        mem_mb=1000
    shell:
        # Use the header from the first file; they should all be identical
        """
        (grep -m1 '^#' $(head -1 {input.argfile}) ; \
         cat {input.argfile} | while read line; do \
            tail -n +2 $line ; \
         done) \
        | bgzip --threads {threads} -c > {output.tabgz}
        tabix -p vcf -S 1 {output.tabgz}
        """


# Needs to match GATK read filters (e.g., mapping quality, additional
# default HaplotypeCaller read filters) to be meaningful.
rule depth_profile_scatter:
    input:
        argfile="gatk/arg_file_bams.list"
    output:
        tmp=temp("depth_profile/gatk_depthofcoverage/region_{analysis_region}.tmp.txt"),
        txt=temp("depth_profile/gatk_depthofcoverage/region_{analysis_region}.txt")
    log:
        "depth_profile/gatk_depthofcoverage/region_{analysis_region}.log"
    benchmark:
        "depth_profile/gatk_depthofcoverage/benchmark_depthofcoverage.region_{analysis_region}.txt"
    params:
        regionflag="-L {analysis_region}"
    threads: 1
    resources:
        mem_mb=6000
    shell:
        """
        gatk DepthOfCoverage \
            --java-options '-Xmx5G -Xms5G' \
            --arguments_file {input.argfile} \
            -R {config[ref]} \
            {params.regionflag} \
            --minimum-mapping-quality 60 \
            --read-filter NotSecondaryAlignmentReadFilter \
            --read-filter GoodCigarReadFilter \
            --read-filter NonZeroReferenceLengthAlignmentReadFilter \
            --read-filter PassesVendorQualityCheckReadFilter \
            --read-filter MappedReadFilter \
            --read-filter MappingQualityAvailableReadFilter \
            --read-filter NotDuplicateReadFilter \
            --read-filter MappingQualityReadFilter \
            --read-filter WellformedReadFilter \
            --omit-interval-statistics true \
            --omit-locus-table true \
            --omit-per-sample-statistics true \
            --output-format TABLE \
            -O {output.tmp}
        {config[scripts]}/totab.depth_profile.sh {output.tmp} {output.txt} \
        """
